#! /usr/bin/env python3

import requests
import threading
import os
import psycopg2
import psycopg2.extras
import json
import hashlib
import time


WATCHED_EXTS = [".sh", ".sql"]
IGNORE_DIRS = [".git"]


def run_sync(attendance_id):
    file_uploader = FileUploader(attendance_id)
    watcher = Watcher(file_uploader, base_path="src")
    while True:
        watcher.poll_for_changes()
        time.sleep(1)


def pg_update():
    pg_executor = PgExec()
    watcher = Watcher(pg_executor, base_path="src")
    while True:
        watcher.poll_for_changes()
        time.sleep(1)


def skiller_whale_sync():
    print("  _____ _    _ _ _            __          ___           _      ")
    print(" / ____| |  (_) | |           \\ \\        / / |         | |     ")
    print("| (___ | | ___| | | ___ _ __   \\ \\  /\\  / /| |__   __ _| | ___ ")
    print(" \\___ \\| |/ / | | |/ _ \\ '__|   \\ \\/  \\/ / | '_ \\ / _` | |/ _ \\")
    print(" ____) |   <| | | |  __/ |       \\  /\\  /  | | | | (_| | |  __/")
    print("|_____/|_|\\_\\_|_|_|\\___|_|        \\/  \\/   |_| |_|\\__,_|_|\\___| ")
    print("")
    attendance_id = os.environ.get("ATTENDANCE_ID")
    print("")
    print(f'We\'re going to start watching this directory for changes so that the trainer can see your progress, using id {attendance_id}')

    sync_thread = threading.Thread(target=run_sync, args=[attendance_id])
    sync_thread.start()

    pg_update()


class PgExec:
    def __init__(self):
        connection_string = os.environ.get("PSYCOPG_CONNECTION_STRING")
        print(connection_string)
        self.connection = psycopg2.connect(connection_string)

    def file_changed(self, path):
        print("")
        print(f'RUNNING FILE {path}')
        print("")
        with open(path, "r") as f:
            contents = f.read()

            with self.connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                cursor.execute(contents)
                results = cursor.fetchall()
                for result in results:
                    print("--- ROW ---")
                    for key in result:
                        print(str(key).upper() + ": " + str(result[key]))
                    print("")


class FileUploader:
    def __init__(self, attendance_id):
        self.attendance_id = attendance_id

    def file_changed(self, path):
        # print("File changed, uploading: %s" % path)
        with open(path, "r") as f:
            data = json.dumps({
                "relative_path": path,
                "contents": f.read()
                })

            hostname = os.environ.get('SERVER_URL', "https://train.skillerwhale.com")
            path = "/attendances/%s/file_snapshots" % self.attendance_id
            uri = requests.compat.urljoin(hostname, path)

            headers = {
                "Content-Type": "application/json",
                "Content-Length": str(len(data))
                }

            response = requests.post(uri, data=data, headers=headers)
            if(response.status_code != 200):
                print(response.status_code)
                txt = response.text
                if txt:
                    print(txt)


class Watcher:
    # TODO: This class is almost identical to the one in the python-essentials
    # repo. We should put these in a consistent place somewhere...
    def __init__(self, responder, base_path='.'):
        self.responder = responder
        self.base_path = base_path
        self._file_hashes = {}
        # Tracks whether this is the first pass of the directory tree. If not,
        # then any new file encountered will be treated as an update.
        self._first_pass = True

    @staticmethod
    def get_file_hash(path):
        """Return a hash digest of the file located at path"""
        with open(path, "rb") as f:
            contents = f.read()
            return hashlib.md5(contents).hexdigest()

    def _respond_to_file_change(self, path):
        _, extension = os.path.splitext(path)
        if extension not in WATCHED_EXTS:
            return

        hashed = self.get_file_hash(path)
        if not self._first_pass:
            old_hash = self._file_hashes.get(path)
            if old_hash != hashed:
                self.responder.file_changed(path)
        self._file_hashes[path] = hashed

    def _check_dir_for_changes(self, dir_path):
        if os.path.basename(dir_path) in IGNORE_DIRS:
            return

        for filename in os.listdir(dir_path):
            new_path = os.path.join(dir_path, filename)
            if os.path.isdir(new_path):
                # Recursively check subdirectories
                self._check_dir_for_changes(new_path)
            else:
                self._respond_to_file_change(new_path)

    def poll_for_changes(self, wait_time=1):
        while True:
            self._check_dir_for_changes(self.base_path)
            self._first_pass = False
            time.sleep(wait_time)  # Poll for changes every `wait_time` seconds


if __name__ == "__main__":
    skiller_whale_sync()
