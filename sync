#! /usr/bin/env python3

import hashlib
import json
import os
import threading
import time
from urllib.parse import urljoin

import requests
import psycopg2
from tabulate import tabulate

import db_init


WATCHED_EXTS = [".sh", ".sql"]
IGNORE_DIRS = [".git"]

SERVER_URL = os.getenv('SERVER_URL', "https://train.skillerwhale.com")
USER_ID_FILEPATH = '/attendance_id'


def run_sync():
    file_uploader = FileUploader()
    pinger = Pinger()
    watcher = Watcher(file_uploader, base_path="src")
    watcher.poll_for_changes(loop_callback=pinger.ping)


def pg_update():
    time.sleep(1)  # Give time for the database service to start
    pg_executor = PgExec()
    watcher = Watcher(pg_executor, base_path="src")
    watcher.poll_for_changes()


def read_attendance_id():
    with open(USER_ID_FILEPATH) as id_file:
        return id_file.read().strip()


def skiller_whale_sync():
    print("  _____ _    _ _ _            __          ___           _      ")
    print(" / ____| |  (_) | |           \\ \\        / / |         | |     ")
    print("| (___ | | ___| | | ___ _ __   \\ \\  /\\  / /| |__   __ _| | ___ ")
    print(" \\___ \\| |/ / | | |/ _ \\ '__|   \\ \\/  \\/ / | '_ \\ / _` | |/ _ \\")
    print(" ____) |   <| | | |  __/ |       \\  /\\  /  | | | | (_| | |  __/")
    print("|_____/|_|\\_\\_|_|_|\\___|_|        \\/  \\/   |_| |_|\\__,_|_|\\___| ")
    print("")
    print("")
    print(f'We\'re going to start watching this directory for changes so that the trainer can see your progress.')
    print(f'Your attendance id is currently set to: {read_attendance_id()}')
    print(f'If this is not correct, you can update it in the file {USER_ID_FILEPATH}\n')

    sync_thread = threading.Thread(target=run_sync)
    sync_thread.start()

    pg_update()


class PgExec:
    DATABASE_NAME_FILE = '.db_name'

    def __init__(self):
        print("Initialising databases")
        db_init.init()
        print("Initialisation complete")

    def execute_sql(self, connection, sql):
        with connection.cursor() as cursor:
            cursor.execute(sql)

            if not cursor.description:  # If no columns are returned
                return [], []

            column_names = [column.name for column in cursor.description]
            return column_names, cursor.fetchall()

    @classmethod
    def get_db_name_from_path(cls, path):
        """Returns the content of a .db_name file in the directory"""
        dir_name, _ = os.path.split(path)
        db_file = os.path.join(dir_name, cls.DATABASE_NAME_FILE)

        if os.path.exists(db_file):
            with open(db_file) as file:
                db_name = file.read().strip()
                if db_name:
                    return db_name

        print(f"\nNo associated database found at {db_file}\n")
        return None


    def file_changed(self, path):
        # Will run a query against the database named according to the path
        database_name = self.get_db_name_from_path(path)
        if not database_name:
            return

        print(f'\nRUNNING FILE {path}')
        with open(path, "r") as f:
            contents = f.read()

        print(f"Querying the database: {database_name}\n")

        # Do not retry - an invalid db name would get stuck in an infinite loop
        connection = db_init.get_connection(database_name, retry_time=None)
        if not connection:
            return  # Database error logging dealt with in get_connection

        try:
            query_columns, query_rows = self.execute_sql(connection, contents)
        except psycopg2.Error as err:
            connection.rollback()
            print("POSTGRES ERROR:", err)
        else:
            print(tabulate(query_rows, headers=query_columns))
            print(f'\nRow Count: {len(query_rows)}\n')
        print()


def create_skiller_whale_url(path):
    return urljoin(SERVER_URL, path)


class FileUploader:
    def get_uri(self, attendance_id):
        return create_skiller_whale_url(self.get_path(attendance_id))

    def get_path(self, attendance_id):
        return f'attendances/{attendance_id}/file_snapshots'

    @staticmethod
    def get_file_data(path):
        with open(path, "r") as f:
            data = {"relative_path": path, "contents": f.read()}
            return json.dumps(data)

    @staticmethod
    def get_headers(data):
        return {
            "Content-Type": "application/json",
            "Content-Length": str(len(data))
        }

    def post_file(self, path, attendance_id):
        data = self.get_file_data(path)
        headers = self.get_headers(data)
        return requests.post(self.get_uri(attendance_id), data=data, headers=headers)

    def file_changed(self, path):
        attendance_id = read_attendance_id()
        print(f"Uploading: {path}", end='\t')
        if not attendance_id:
            print("No attendance id set; file update not sent.")
            return

        try:
            response = self.post_file(path, attendance_id)
        except requests.exceptions.ConnectionError:
            print(f"Failed\nCould not reach {SERVER_URL}")
        else:
            print(f"Status: {response.status_code}")
            if response.text:
                print(response.text)


class Pinger:
    @property
    def uri(self):
        return create_skiller_whale_url(self.path)

    @property
    def path(self):
        attendance_id = read_attendance_id()
        return f'attendances/{attendance_id}/pings'

    def ping(self):
        try:
            requests.post(self.uri)
        except requests.exceptions.ConnectionError:
            pass  # Tolerate failed pings


class Watcher:
    def __init__(self, responder, base_path='.'):
        self.responder = responder
        self.base_path = base_path
        self._file_hashes = {}
        # Tracks whether this is the first pass of the directory tree. If not,
        # then any new file encountered will be treated as an update.
        self._first_pass = True

    @staticmethod
    def get_file_hash(path):
        """Return a hash digest of the file located at path"""
        with open(path, "rb") as f:
            contents = f.read()
            return hashlib.md5(contents).hexdigest()

    def _respond_to_file_change(self, path):
        _, extension = os.path.splitext(path)
        if extension not in WATCHED_EXTS:
            return

        hashed = self.get_file_hash(path)
        if not self._first_pass:
            old_hash = self._file_hashes.get(path)
            if old_hash != hashed:
                try:
                    self.responder.file_changed(path)
                except Exception as err:
                    print("Unexpected error:", err)
        self._file_hashes[path] = hashed

    def _check_dir_for_changes(self, dir_path):
        if os.path.basename(dir_path) in IGNORE_DIRS:
            return

        for filename in os.listdir(dir_path):
            new_path = os.path.join(dir_path, filename)
            if os.path.isdir(new_path):
                # Recursively check subdirectories
                self._check_dir_for_changes(new_path)
            else:
                self._respond_to_file_change(new_path)

    def poll_for_changes(self, wait_time=1, loop_callback=lambda: None):
        """Optionally specify loop_callback, which is called each iteration"""
        while True:
            try:
                loop_callback()
            except Exception as err:
                print("Unexpected callback error:", err)

            try:
                self._check_dir_for_changes(self.base_path)
            except Exception as err:
                print("Unexpected error in file watcher:", err)
            else:
                self._first_pass = False

            time.sleep(wait_time)  # Poll for changes every `wait_time` seconds


if __name__ == "__main__":
    skiller_whale_sync()
